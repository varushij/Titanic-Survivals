# Titanic-Survivals
Titanic Survivals (Kaggle competition) <br />
The Titanic tragedy is something everyone is aware of. Many innocent people died in this tragedy, making it one of the most tragic shipwreck in history. <br />
In this project we aim to analyse the different types of people who had higher chances of survival in this tragdedy.<br />
This is a supervised binary classsification problem, where we try to predict the survival of passengers based on various factors like the class in which they were travelling, passenger's age and gender etc.


# Prerequisites
The project was developed using jupyter notebook (version 4.4.0) with Python 3.
To run this project, following libraries needs to be installed - 
* Numpy
* Pandas
* Matplotlib
* Missingno
* Seaborn
* Sklearn

# Algorithms used
* Logistic Regression
* K-Nearest Neighbor
* Support Vector Machines
* Naive Bayes
* Decision Trees <br />
**Finally, Decision Trees model was used on the test set to make the prediction of survival rate of passengers as it had the highest accuracy.**

__This submission on Kaggle secured a public score of 0.77511.__

# References
https://realpython.com/python-data-cleaning-numpy-pandas/ <br />
http://www.titanicandco.com/inside.html <br />
https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/ <br />
https://www.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html <br />
https://towardsdatascience.com/supervised-machine-learning-classification-5e685fe18a6d <br />
https://blog.goodaudience.com/machine-learning-using-logistic-regression-in-python-with-code-ab3c7f5f3bed <br />
https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/ <br />
https://towardsdatascience.com/precision-vs-recall-386cf9f89488 <br />
